{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommy/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00154083]\n",
      " [0.00699301]]\n"
     ]
    }
   ],
   "source": [
    "data_set = []\n",
    "label_set = []\n",
    "for i in range(1,1001):\n",
    "    data = [1.0/i]\n",
    "    label = [1.0/i]\n",
    "    data_set.append(data)\n",
    "    label_set.append(label)\n",
    "data_set=np.array(data_set)\n",
    "label_set=np.array(label_set)\n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "data_set,label_set = unison_shuffled_copies(data_set,label_set)\n",
    "print(data_set[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11946488\n",
      "0.44358623\n",
      "0.09755578\n",
      "0.034890607\n",
      "0.20631625\n",
      "0.15162489\n",
      "0.019592391\n",
      "0.03032659\n",
      "0.103214525\n",
      "0.10095323\n",
      "[array([0.0212766])]\n",
      "[array([[0.21093656]], dtype=float32)]\n",
      "[0.0212766]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Model(object):\n",
    "    def __init__(self):\n",
    "        self.input = tf.placeholder(tf.float32,shape=[None,1],name='input')\n",
    "        self.label = tf.placeholder(tf.float32,shape=[None,1],name='label')\n",
    "        self.global_step = tf.Variable(0, name='global_step',trainable=False)\n",
    "        self.keep_prob = tf.placeholder(tf.float32,name='keep_prob')\n",
    "        \n",
    "    def denselayer_with_dropout(self, input_, out_dim , keep_prob):\n",
    "        '''\n",
    "        dense = tf.layers.dense(inputs=input_, units= out_dim , use_bias = False,\n",
    "                                activation=tf.nn.relu)#tf.nn.relu\n",
    "        return dense\n",
    "        '''\n",
    "        w = tf.Variable(tf.random_normal([]), name='weight')\n",
    "        b = tf.Variable(tf.random_normal([]), name='bias')\n",
    "        nonlin_model = tf.add(tf.multiply(tf.tanh(input_), w), b)\n",
    "        return nonlin_model\n",
    "    \n",
    "    def inference(self):\n",
    "        dense_out = self.denselayer_with_dropout(self.input,1,1)\n",
    "        return dense_out\n",
    "    \n",
    "    def build_optimizer(self,loss_val,trainable_var,learning_rate):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate) \n",
    "        grads = optimizer.compute_gradients(loss_val, var_list=trainable_var)\n",
    "        return optimizer.apply_gradients(grads,global_step=self.global_step)\n",
    "        \n",
    "    def build_train(self,learning_rate):\n",
    "        raw_output = self.inference()\n",
    "        rawloss = tf.losses.mean_squared_error(self.label,raw_output)\n",
    "        loss = tf.reduce_mean(rawloss)\n",
    "        trainable_var = tf.trainable_variables()\n",
    "        train_op = self.build_optimizer(loss,trainable_var,learning_rate)\n",
    "        return train_op,loss,raw_output\n",
    "    \n",
    "    def before_session_initialization(self,learning_rate):\n",
    "        self.train_op,self.loss_op, self.raw_out = self.build_train(\n",
    "            learning_rate=learning_rate)\n",
    "        \n",
    "    def after_session_initialization(self,sess):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        self.train_writer = tf.summary.FileWriter('./', sess.graph)\n",
    "        \n",
    "    def train(self,sess,data,label):\n",
    "        for i in range(10):\n",
    "            batch_data = data[i*100:(i+1)*100]\n",
    "            batch_label = label[i*100:(i+1)*100]\n",
    "            feed_dict = {self.input: batch_data, self.label: batch_label}\n",
    "            _, train_loss,out= sess.run([self.train_op,self.loss_op,self.raw_out], feed_dict=feed_dict)\n",
    "            print(train_loss)\n",
    "            #print(out)\n",
    "            #print(batch_label)\n",
    "            \n",
    "    def test(self,sess,data):\n",
    "        inp = [data]\n",
    "        print(inp)\n",
    "        feed_dict = {self.input: [data]}\n",
    "        out= sess.run([self.raw_out], feed_dict=feed_dict)\n",
    "        print(out)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "model = Model()\n",
    "model.before_session_initialization(learning_rate=1)\n",
    "sess = tf.InteractiveSession()\n",
    "model.after_session_initialization(sess)\n",
    "model.train(sess,data_set,label_set)\n",
    "model.test(sess,data_set[200])\n",
    "print(label_set[200])\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from omnicomm_data.test_data import get_model\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline \n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "# tf variables\n",
    "x_ = tf.placeholder(name=\"input\", shape=[None, 1], dtype=np.float32)\n",
    "y_ = tf.placeholder(name=\"output\", shape=[None, 1], dtype=np.float32)\n",
    "w = tf.Variable(tf.random_normal([]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([]), name='bias')\n",
    "\n",
    "# nonlinear\n",
    "nonlin_model = tf.add(tf.multiply(tf.tanh(x_), w), b)\n",
    "nonlin_loss = tf.reduce_mean(tf.pow(nonlin_model - y_, 2), name='cost')\n",
    "train_step_nonlin = tf.train.GradientDescentOptimizer(0.01).minimize(nonlin_loss)\n",
    "\n",
    "\n",
    "# pandas data\n",
    "df_train = pd.read_csv('me_rate.csv', header=None)\n",
    "\n",
    "\n",
    "liters = df_train.iloc[:, 0].values.reshape(-1, 1)\n",
    "parrots = df_train.iloc[:, 1].values.reshape(-1, 1)\n",
    "\n",
    "\n",
    "#model for prediction\n",
    "mms = preprocessing.MinMaxScaler()\n",
    "rbf = get_model(path_to_model)\n",
    "\n",
    "\n",
    "nz = preprocessing.MaxAbsScaler()  # normalization coz tanh\n",
    "norm_parrots = nz.fit_transform(parrots)\n",
    "print(norm_parrots)\n",
    "\n",
    "n_epochs = 20000\n",
    "train_errors = []\n",
    "non_train_errors = []\n",
    "test_errors = []\n",
    "weights = []\n",
    "biases = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in tqdm.tqdm(range(n_epochs)):\n",
    "\n",
    "        _, non_train_err, weight, bias = sess.run([train_step_nonlin, nonlin_loss, w, b],\n",
    "                                      feed_dict={x_: norm_parrots, y_: liters})\n",
    "        non_train_errors.append(non_train_err)\n",
    "        weights.append(weight)\n",
    "        biases.append(bias)\n",
    "\n",
    "\n",
    "    plt.scatter(norm_parrots, liters, label='actual data')\n",
    "\n",
    "    plt.plot(norm_parrots, sess.run(nonlin_model, feed_dict={x_: norm_parrots}), c='orange', label='nonlinear (tf)')\n",
    "    plt.plot(norm_parrots, rbf.predict(mms.fit_transform(parrots)), label='rbf (sklearn)')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
